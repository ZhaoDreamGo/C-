
基础概念
链表
定义：
链表是一种递归的数据结构，它或者为空（null），或者是指向一个结点（node）的引用，该节点还有一个元素和一个指向另1/2条链表的引用（1.单向链表,2.双向链表）。
支持：插入，删除
优势：操作的时间复杂度为O(1)
不足：不支持高效的random access

Q：为什么不支持修改?
A:引用是一个变量的别名。和指针主要有3点不同：1.不存在空引用。引用必须连接到一块合法的内存。2.一旦引用被初始化为一个对象，就不能被指向到另一个对象。指针可以在任何时候指向到另一个对象。3.引用必须在创建时被初始化。指针可以在任何时间被初始化。

堆栈，优先队列
数据结构

堆（完全二叉树，优先队列）
计算机科学中的一种特别的树状数据结构。若是满足以下特性，即可称为堆：“给定堆中任意节点P 和 C，若 P 是 C 的母节点，那么 P 的值会小于等于 C 的值”。若母节点的值恒小于等于子节点的值，此堆称为最小堆；反之，若母节点的值恒大于等于子节点的值，此堆称为最大堆。

栈（LIFO）
运算受限的线性表。其限制是仅允许在表的一端进行插入和删除运算。这一端被称为栈顶，相对地，把另一端称为栈底。

优先队列
优先队列包括最大优先队列和最小优先队列。优先队列中的每个元素都有各自的优先级，优先级最高的元素最先得到服务；优先级相同的元素按照其在优先队列中的顺序得到服务。优先队列往往用堆来实现。

内存区域
程序运行的时候，需要内存空间存放数据

栈（stack）
有结构，每个区块按照一定次序存放，可以明确知道每个区块的大小。
堆（heap）
没有结构，数据可以任意存放。
对比
stack的寻址速度要快于heap
每个线程分配一个stack，每个进程分配一个heap，也就是说，stack是线程独占的，heap是线程共用的。此外，stack创建的时候，大小是确定的，数据超过这个大小，就发生stack overflow错误，而heap的大小是不确定的，需要的话可以不断增加。
只要是局部的、占用空间确定的数据，一般都存放在stack里面，否则就放在heap里面
https://www.cnblogs.com/kevinGaoblog/archive/2012/03/23/2413102.html
二叉树
每个结点最多有两个子树的树结构，递归定义
性质

叶结点数为N0，而度数为2的结点总数为N2，则N0=N2+1
n个结点的完全二叉树的深度为[log_2n]+1[log
​2
​​ n]+1

i个枝点，I为所有枝点的道路长度总和，J为叶的道路长度总和J=I+2i

给定n个节点，能构成h(n)种不同的二叉树 h(n)=C(2^n,n)/(n+1)

类别

满二叉树
深度k,节点数2^k-1
完全二叉树
除最后一层外，其余层都是满的二叉树
二叉查找树
二叉排序树=二叉查找树=二叉搜索树
是一颗空树，或具有以下性质：
a. 若左子树不空，左子树的节点均小于其根节点；
b. 若右子树不空，右子树的节点均大于其根节点；
c. 左右子树也分别是二叉排序树
在最好的情况下，二叉排序树的查找效率是 O(logn)，近似于折半查找；
最差时是 O(n)，比如插入的元素是有序的，生成的二叉排序树就是一个链表
平衡二叉树
它是一棵二叉排序树，且具有以下性质：
a.它是一棵空树或它的左右两个子树的高度差的绝对值不超过1
b.左右两个子树都是一棵平衡二叉树。
平衡二叉树在添加和删除时需要进行旋转保持整个树的平衡,防止二叉查找树的最坏情况发生。插入、查找的时间复杂度都是 O(logn)。
trie字典树
trie，又称前缀树或字典樹，是一种有序树，用于保存关联数组，其中的键通常是字符串。 与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。
性质：
a.根节点不包含字符，除根节点外的每一个子节点都包含一个字符
b.从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串
c.每个节点的所有子节点包含的字符互不相同
插入，查询的效率O(n)
空间换时间

图
基本遍历
遍历：
从图的某个顶点出发访问遍图中所有顶点，且每个顶点仅被访问一次。

深度优先 (DFS)
1、访问指定的起始顶点；
2、若当前访问的顶点的邻接顶点有未被访问的，则任选一个访问之；反之，退回到最近访问过的顶点；直到与起始顶点相通的全部顶点都访问完毕；
3、若此时图中尚有顶点未被访问，则再选其中一个顶点作为起始顶点并访问之，转 2； 反之，遍历结束。
适合题目：
给定初始状态跟目标状态，要求判断从初始状态到目标状态是否有解。
复杂度：
邻接链表：O（N+E）
数组：O（n^2）
广度优先 (BFS)
从图的某一结点出发，首先依次访问该结点的所有邻接顶点 Vi1, Vi2, …, Vin 再按这些顶点被访问的先后次序依次访问与它们相邻接的所有未被访问的顶点，重复此过程，直至所有顶点均被访问为止。
依靠队列和一维数组实现
DFS用递归的形式，用到了栈结构，先进后出。
BFS选取状态用队列的形式，先进先出。
DFS适合目标明确，而BFS适合大范围的寻找。

A搜索
估值函数 f(n)=g(n)+h(n)
g(n)：从搜索点到当前点的代价
h(n):从当前点到目标点的估值
一种具有f(n)=g(n)+h(n)策略的启发式算法能成为A算法的充分条件是
a. 搜索树上存在从起始点到终了点的最优路径
b. 问题域是有限的
c. 所有结点的子结点搜索价值>0
d. h(n)<=h(n) (h(n)为实际问题的代价值)
最短路径算法

Dijkstra
解决带（非负）权重 有向图中单个源点到其他顶点的最短路径问题。
贪心
Bellman-Ford
求单源最短路，可判断有无负权回路。存在负权回路则不存在最短路
时效性好，O（VE）
SPFA：时间复杂度O(kE),有点像带松弛的Dijkstra
Floyd-Warshall
求多源，无负值环路的最短路。用矩阵记录图。时效性较差，时间复杂度O(V^3)。此算法是解决任意两点间的最短路径的一种算法，可以正确处理有向图或负权的最短路径问题。
所有结点对最短路径问题的递归解
最小生成树
连通无向图中，一个连接了所有结点且具有最小权重的树。
都是贪心算法

Prim
从任意一个点出发，每次加入的边都是使得权重和增加最少的边(和Dijkstra相似)
Kruskal
创建V棵树，按照权重从低至高对每条边逐一检查，选择权重低且不在同一棵树的边加入集合。
图匹配
设G=(V,E)是一个无向图。如顶点集V可分区为两个互不相交的子集V1,V2之并，并且图中每条边依附的两个顶点都分属于这两个不同的子集。则称图G为二分图。二分图也可记为G=(V1,V2,E)
给定一个二分图G，在G的一个子图M中，M的边集{E}中的任意两条边都不依附于同一个顶点，则称M是一个匹配（每个顶点最多只出一条边）。 选择这样的子集中边数最大的子集称为图的最大匹配问题(maximal matching problem)
如果一个匹配中，图中的每个顶点都和图中某条边相关联，则称此匹配为完全匹配，也称作完备，完美匹配。

匈牙利算法
用来解决二分图最大匹配问题
若P是图G中一条连通两个未匹配顶点的路径，并且属于M的边和不属于M的边(即已匹配和待匹配的边)在P上交替出现，则称P为相对于M的一条增广路径。
由增广路的定义可以推出下述三个结论：
1－P的路径长度必定为奇数，第一条边和最后一条边都不属于M。
2－将M和P进行异或操作(去同存异)可以得到一个更大的匹配M’。
3－M为G的最大匹配当且仅当不存在M的增广路径。
算法轮廓：
(1)置M为空
(2)找出一条增广路径P，通过异或操作获得更大的匹配M’代替M
(3)重复(2)操作直到找不出增广路径为止
III、时间复杂度与空间复杂度
时间复杂度
邻接矩阵：最坏为O(n^3) 邻接表：O(mn) 　　
空间复杂度：
邻接矩阵：O(n^2) 邻接表：O(m+n)
强连通分支算法与网络流

Ford-Fulkerson
计算网络流的贪心算法，时间复杂度是O(VE^2)
一个结点净流量为0，反向对称，每条边上的流都不超过边的最大流量
从源点出发至最终结点的流量，最大不超过源点流量和终点流量。
复杂度
https://juejin.im/post/58ca051f61ff4b0060165122
（各普通算法的复杂度）
核心：关注问题规模增长后的变化。
时间复杂度
找出算法中的基本语句（执行最多次数的语句）- 计算基本语句的执行次数的数量级（关注最高次幂）- 将基本语句执行次数的数量级放入大Ο记号
注意：
1.并列执行的计算复杂度是加和，循环结构复杂度相乘
2.如果算法的执行时间不随着问题规模n的增加而增长，即使算法中有上千条语句，其执行时间也不过是一个较大的常数。此类算法的时间复杂度是O(1)
空间复杂度
一个算法在计算机存储器上所占用的存储空间，包括存储算法本身，算法的输入输出数据和算法在运行过程中临时占用的存储空间三个方面，可变的空间复杂度是算法在运行过程中临时占用的存储空间，主要计算这一部分。
注意：
O(1)是说数据规模和临时变量数目无关，并不是说仅仅定义一个临时变量。举例：无论数据规模多大，我都定义100个变量，这就叫做数据规模和临时变量数目无关。就是说空间复杂度是O(1)。

集合和映射
臧老师说：
python的set和dict相当于 c++ 的 unordered_set 和 unordered_map，是用哈希实现的,c++的set和map是用平衡树实现的。
ordered dict：双向链表

贪心算法
每一步选当前最好的，不从整体上考虑，仅考虑局部最优。
求解问题分成多干子问题-每个子问题求解，得到局部最优解-子问题的解合并成原问题的一个解。
贪心算法适用的情况很少，能用的前提证明是局部最优策略能导致产生全局最优解。

动态规划
适合于问题的最优解所包含的子问题的解也是最优的，我们就称该问题具有最优子结构性质（即满足最优化原理）；无后效性，即子问题的解一旦确定，就不再改变，不受在这之后、包含它的更大的问题的求解决策影响；用递归算法自顶向下对问题进行求解时，每次产生的子问题并不总是新问题，有些子问题会被重复计算多次（子问题重叠性质）。

动态规划法试图仅仅解决每个子问题一次，从而减少计算量：一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。
划分问题-确定状态和变量-确定决策及状态转移方程-寻找边界条件（终止递归）
相关算法
最长公共子序列，Floyd-Warshall，维特比算法等。

分治
将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之。子问题互相独立（动态规划中一些子问题是其余子问题的基础）且与原问题形式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解。

分解（将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题）-解决（若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题）-合并（将各个子问题的解合并为原问题的解）
经典问题
（1）二分搜索
（2）大整数乘法
（3）Strassen矩阵乘法
（4）棋盘覆盖
（5）合并排序
（6）快速排序
（7）线性时间选择
（8）最接近点对问题
（9）循环赛日程表
（10）汉诺塔

递归
函数调用自身。需明确递归结束的条件，避免函数无限调用。
初始化算法-判别当前值是直接返回还是接着递归-划分成小问题运算-对子问题进行算法-结果合并入答案的表达式-返回
应用范围：
（1）数据的定义是按递归定义的。（比如Fibonacci函数）
（2）问题解法按递归算法实现。（回溯）
（3）数据的结构形式是按递归定义的。（比如树的遍历，图的搜索）
优点：
递归使代码看起来更加整洁、优雅
可以用递归将复杂任务分解成更简单的子问题
使用递归比使用一些嵌套迭代更容易
缺点：
递归的逻辑很难调试、跟进
递归算法解题的运行效率较低。在递归调用的过程当中系统为每一层的返回点、局部量等开辟了栈来存储。递归次数过多容易造成栈溢出等。

Q：递归和迭代的区别？
A：迭代利用变量的原值推算出变量的一个新值。如果递归是自己调用自己的话,迭代就是A不停的调用B。递归中一定有迭代,但是迭代中不一定有递归,大部分可以相互转换。能用迭代的不用递归,递归调用函数,浪费空间,并且递归太深容易造成堆栈的溢出。

搜索
搜索算法是利用计算机的高性能来有目的的穷举一个问题解空间的部分或所有的可能情况，从而求出问题的解的一种方法。
主要方法：

顺序查找：顺序存储或链接存储的线性表
二分查找：元素有序时，进行折半查找
插值查找：在二分查找基础上，自适应地选择切入值
斐波那契查找：在二分查找基础上，将待比较区间的元素个数按0.618比例划分
树表查找：
a. 二叉树查找算法
生成树，左分枝小于右分支，和父节点比较大小，查找适合的范围
b. 平衡查找树之2-3查找树
如果中序遍历2-3查找树，就可以得到排好序的序列；
在一个完全平衡的2-3查找树中，根节点到每一个为空节点的距离都相同。
c.平衡查找树之红黑树
d.B树和B+树
分块查找：
索引顺序查找。将n个数据元素”按块有序”划分为m块（m ≤ n）。每一块中的结点不必有序，但块与块之间必须”按块有序”（即第1块中任一元素的关键字都必须小于第2块中任一元素的关键字）
选取各块中的最大关键字构成一个索引表-先对索引表进行二分查找或顺序查找，以确定待查记录在哪一块中；然后，在已确定的块中用顺序法进行查找
hash查找（map,dict）：
以空间换时间。
使用一个下标范围比较大的数组来存储元素。可以设计一个函数（哈希函数， 也叫做散列函数），使得每个元素的关键字都与一个函数值（即数组下标）相对应，于是用这个数组单元来存储这个元素；也可以简单的理解为，按照关键字为每一个元素”分类”，然后将这个元素存储在相应”类”所对应的地方。但是，不能够保证每个元素的关键字与函数值是一一对应的，因此极有可能出现对于不同的元素，却计算出了相同的函数值，这样就产生了”冲突”，换句话说，就是把不同的元素分在了相同的”类”之中。后面我们将看到一种解决”冲突”的简便做法。
”直接定址”与”解决冲突”是哈希表的两大特点。
哈希函数的规则是：通过某种转换关系，使关键字适度的分散到指定大小的的顺序结构中，越分散，则以后查找的时间复杂度越小，空间复杂度越高。
算法思想：哈希的思路很简单，如果所有的键都是整数，那么就可以使用一个简单的无序数组来实现：将键作为索引，值即为其对应的值，这样就可以快速访问任意键的值。这是对于简单的键的情况，我们将其扩展到可以处理更加复杂的类型的键。
用给定的哈希函数构造哈希表-根据选择的冲突处理方法解决地址冲突
深度优先(栈)：用最优性和可行性剪枝优化
广度优先（队列）：用hash判重和双向搜索优化
排序
https://www.cnblogs.com/onepixel/articles/7674659.html

冒泡排序
一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换
选择排序
首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。
插入排序
它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。
希尔排序
也叫缩小增量排序，它会优先比较距离较远的元素是插入排序的改进版。
1.选择一个增量序列t1，t2，…，tk，其中ti>tj，tk=1；
2.按增量序列个数k，对序列进行k 趟排序；
3.每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。
即分成k个序列进行插入排序
归并排序
分治法的应用。将已有序的子序列合并，得到完全有序的序列。
快速排序
分治法的应用。通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。
堆排序
利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。
初始都是无序区-把最大（小）的元素推到堆顶-随即将堆顶元素和最后一个无序元素交换-不断更新堆顶，直至所有元素有序。
计数排序
将输入的数据值转化为键存储在额外开辟的数组空间中。要求输入的数据必须是有确定范围的整数。
找出待排序的数组中最大和最小的元素-统计数组中每个值为i的元素出现的次数，存入数组C的第i项-对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）-反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。
当k不是很大并且序列比较集中时，计数排序是一个很有效的排序算法
桶排序
桶排序是计数排序的升级版。假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。
设置一个定量的数组当作空桶-遍历输入数据，并且把数据一个一个放到对应的桶里去-对每个不是空的桶进行排序-从不是空的桶里把排好序的数据拼接起来。
基数排序
按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。
高效算法设计
一. 渐进复杂度
最大连续和问题

O（n^3n
​3
​​ ）
普通分析法：
对于每个元素为起点 的 长度有多种可能 求和 ，加法操作的次数
上界分析法：
每层循环假定最坏情况，粗粗计算

O(n^2n
​2
​​ )
连续子序列之和等于两个前缀和之差
求和的那层子循环可以去掉了

O(nlogn)
分治法:划分问题-递归求解（子）问题-合并子解得到最优解

O(n)
被减数前缀和确定时，减数前缀和最小，差值越大
Q：算好全部前缀和复杂度是n,可是j有n种可能啊！难道扫描不算时间复杂度？
A: 扫描当然算时间复杂度，O(n)+O(n)复杂度还是O(n),复杂度的变化表征数据规模变化后运算量与之前的相比的倍数，不要把乘和加的关系弄混。
二. 线段树与树状数组
线段树来存放给定区间内对应信息的一种数据结构,与树状数组相似，线段树也用来处理数组相应的区间查询和元素更新操作。与树状数组不同的是，线段树不止可以适用于区间求和的查询，也可以进行区间最大值，区间最小值或者区间异或值的查询。完全二叉树来实现。
二者更新和查询的复杂度都是O（logn）。
用树状数组能够解决的问题，用线段树肯定能够解决，反之则不一定。但是树状数组有一个明显的好处就是较为节省空间，实现要比线段树要容易得多，而且在处理某些问题的时候使用树状数组效率反而会高得多。